{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "import os\n",
    "import csv \n",
    "import pandas as pd\n",
    "import statistics as stat\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#Utility (Optional)\n",
    "clear = lambda: os.system('cls')\n",
    "clear()\n",
    "\n",
    "#STEP 1 : COUNT ALL SIMILARITIES IN 1 ROW\n",
    "#STEP 2 : IF COUNTED SIMILARITIES MORE THAN 37, DELETE COLUMN\n",
    "\n",
    "dtTrain = pd.read_csv(\"data/TrainSetNoId.csv\")\n",
    "dtTrainRaw = dtTrain\n",
    "# dtCdk = pd.read_csv(\"data/cdk_desc.csv\", delimiter=' ')\n",
    "\n",
    "def similarValue(dframe):\n",
    "    colList = [] #List for column\n",
    "    # colDframe = dframe.columns.values #get all columns\n",
    "    for j in range(0,dframe.shape[1]):\n",
    "        topEl = stat.mode(dframe.iloc[:,j]) # Get modus value from j column\n",
    "        duplicate = 0\n",
    "        # Loop comparing each row with modus\n",
    "        for i in range(0,74):\n",
    "            comp = dframe.iloc[i,j]\n",
    "            if comp == topEl:\n",
    "                duplicate += 1\n",
    "        if duplicate >= 37 :\n",
    "            colList.append(j)    \n",
    "    return colList\n",
    "\n",
    "def stdDeviation(dframe):\n",
    "    stdevList = []\n",
    "    # colDframe = dframe.columns.values\n",
    "    for j in range(0,dframe.shape[1]-1):\n",
    "        # Loop search standard deviation each column\n",
    "        stddev = 0\n",
    "        sample = dframe.iloc[:,j] #Get all row in j column for standard deviation\n",
    "        stddev = np.std(sample) #Get standard deviation from 'sample' list\n",
    "        if stddev <= 0.95 :\n",
    "            # print(j, \"PICKED\")\n",
    "            stdevList.append(j)\n",
    "    return stdevList\n",
    "\n",
    "def checkNa(dframe):\n",
    "    naList = []\n",
    "    # colDframe = dframe.columns.values\n",
    "    for j in range(0,dframe.shape[1]):\n",
    "        cknan = dframe.iloc[0,j]\n",
    "        if math.isnan(cknan): #Check NaN value at row 0 in column j\n",
    "            naList.append(j)\n",
    "    return naList\n",
    "\n",
    "def checkInf(dframe):\n",
    "    infList = []\n",
    "    colDframe = dframe.columns.values\n",
    "    for j in range(0,len(colDframe)):\n",
    "        cknan = dframe.iloc[0,j]\n",
    "        if math.isinf(cknan): #Check Infinite value at row 0 in column j\n",
    "            infList.append(j)\n",
    "    return infList\n",
    "\n",
    "def checkDupLabel(dframe):\n",
    "    dupLabel = []\n",
    "    for i in range(0,dframe.shape[1]):\n",
    "        label = dframe.columns.values[i]\n",
    "        for j in range(i+1, dframe.shape[1]):\n",
    "            if(label == dframe.columns.values[j]):\n",
    "                print(0)\n",
    "    return dupLabel\n",
    "\n",
    "def lowCorrP(dframe):\n",
    "    label_ = dframe.columns.values\n",
    "    pic50 = dframe.iloc[:,-1]\n",
    "    corr_y = [pearsonr(dframe.iloc[:,i],pic50) for i in range(dframe.shape[1])]\n",
    "    corr_y = [np.abs(corr_y[i][0]) for i in range(dframe.shape[1])]\n",
    "    corr_lim = 0.20\n",
    "    hi_corr = []\n",
    "    for i in range(len(corr_y)):\n",
    "        if corr_y[i] > corr_lim:\n",
    "            hi_corr.append(i)\n",
    "    label_idx = label_[hi_corr]\n",
    "    dtLowCorr = dframe.loc[:,label_idx]\n",
    "    # print(X_train)\n",
    "    print(\"descriptor number after removing low correlation with target: {}\".format(dtLowCorr.shape[1]))\n",
    "    return dtLowCorr\n",
    "\n",
    "def highCorrP(dframe):\n",
    "    # -----------REMOVE FEATURE WITH HIGH CORRELATION TO OTHER FEATURE---------------------\n",
    "    # re-calculate correlation with pic50\n",
    "    label_ = dframe.columns.values\n",
    "    pic50 = dframe.iloc[:,-1]\n",
    "    corr_y = [pearsonr(dframe.iloc[:,i],pic50) for i in range(dframe.shape[1])]\n",
    "    corr_y = [np.abs(corr_y[i][0]) for i in range(dframe.shape[1])]\n",
    "    desc_num = dframe.shape[1]\n",
    "    # calculate correlation for each descriptor\n",
    "    corr_matrix = np.corrcoef(dframe.T)\n",
    "    corr_lim = 0.80\n",
    "    low_corr = np.arange(desc_num).tolist()\n",
    "    tmp = np.arange(desc_num).tolist()\n",
    "    for i in np.arange(desc_num):\n",
    "        tmp.remove(i)\n",
    "        for j in tmp:\n",
    "            corr_ = np.abs(corr_matrix[i,j])\n",
    "            if corr_ >= corr_lim:\n",
    "                if corr_y[i] > corr_y[j]:\n",
    "                    if j in low_corr:\n",
    "                        low_corr.remove(j)\n",
    "                else:\n",
    "                    if i in low_corr:\n",
    "                        low_corr.remove(i)\n",
    "    label_idx = label_[low_corr]\n",
    "    dtHiCorr = dframe.loc[:,label_idx]\n",
    "    print(\"descriptor number after removing high correlation descriptor: {}\".format(dtHiCorr.shape[1]))\n",
    "    return dtHiCorr\n",
    "\n",
    "def dropColumn(dframe, tList):\n",
    "    dropped = pd.DataFrame() #Create empty dataframe\n",
    "    dropped = dframe.drop(dframe.columns[tList], axis=1) #drop column based on list by column\n",
    "    return dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ########## START HERE ##########\n",
    "# #Create Nan Values List\n",
    "# naValues = []\n",
    "# print(\"#Trainset After Concatenated : \", dtTrain.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0. Trainset  3609  |  166  NaN value columns removed\n"
     ]
    }
   ],
   "source": [
    "##### STEP 0 Reduces NAN Values\n",
    "raw = len(dtTrain.columns)\n",
    "dtTrain.dropna(axis=1, how='any', thresh=None, subset=None, inplace=True)\n",
    "print(\"#0. Trainset \", dtTrain.shape[1] , \" | \", raw-dtTrain.shape[1], \" NaN value columns removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1. Trainset  3609  |  2627  similarity value columns removed\n"
     ]
    }
   ],
   "source": [
    "##### STEP 1 Reduces similarity\n",
    "simValList = similarValue(dtTrain)\n",
    "print(\"#1. Trainset \", dtTrain.shape[1] , \" | \", dtTrain.shape[1] - len(simValList) , \" similarity value columns removed\")\n",
    "dtTrain = dropColumn(dtTrain,simValList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2. Trainset  2627  |  1287  standard deviation below 0.95 value columns removed\n"
     ]
    }
   ],
   "source": [
    "##### STEP 2 Reduce columns by Standard Deviation\n",
    "sdList = stdDeviation(dtTrain)\n",
    "print(\"#2. Trainset \", dtTrain.shape[1] , \" | \", dtTrain.shape[1] - len(sdList) , \" standard deviation below 0.95 value columns removed\")\n",
    "dtTrain = dropColumn(dtTrain,sdList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptor number after removing low correlation with target: 1083\n"
     ]
    }
   ],
   "source": [
    "###### STEP 3  Low Correlations\n",
    "dtTrain = lowCorrP(dtTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptor number after removing high correlation descriptor: 73\n"
     ]
    }
   ],
   "source": [
    "###### STEP 4 High Correlations\n",
    "dtTrain = highCorrP(dtTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtTrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
