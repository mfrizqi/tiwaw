{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "import os\n",
    "import csv \n",
    "import pandas as pd\n",
    "import statistics as stat\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#Utility (Optional)\n",
    "clear = lambda: os.system('cls')\n",
    "clear()\n",
    "\n",
    "#STEP 1 : COUNT ALL SIMILARITIES IN 1 ROW\n",
    "#STEP 2 : IF COUNTED SIMILARITIES MORE THAN 37, DELETE COLUMN\n",
    "\n",
    "dtTrain = pd.read_csv(\"data/TrainSetNoId.csv\")\n",
    "dtTrainRaw = dtTrain\n",
    "# dtCdk = pd.read_csv(\"data/cdk_desc.csv\", delimiter=' ')\n",
    "\n",
    "def similarValue(dframe):\n",
    "    colList = [] #List for column\n",
    "    # colDframe = dframe.columns.values #get all columns\n",
    "    for j in range(0,dframe.shape[1]):\n",
    "        topEl = stat.mode(dframe.iloc[:,j]) # Get modus value from j column\n",
    "        duplicate = 0\n",
    "        # Loop comparing each row with modus\n",
    "        for i in range(0,74):\n",
    "            comp = dframe.iloc[i,j]\n",
    "            if comp == topEl:\n",
    "                duplicate += 1\n",
    "        if duplicate >= 37 :\n",
    "            colList.append(j)    \n",
    "    return colList\n",
    "\n",
    "def stdDeviation(dframe):\n",
    "    stdevList = []\n",
    "    # colDframe = dframe.columns.values\n",
    "    for j in range(0,dframe.shape[1]-1):\n",
    "        # Loop search standard deviation each column\n",
    "        stddev = 0\n",
    "        sample = dframe.iloc[:,j] #Get all row in j column for standard deviation\n",
    "        stddev = np.std(sample) #Get standard deviation from 'sample' list\n",
    "        if stddev <= 0.95 :\n",
    "            # print(j, \"PICKED\")\n",
    "            stdevList.append(j)\n",
    "    return stdevList\n",
    "\n",
    "def checkNa(dframe):\n",
    "    naList = []\n",
    "    # colDframe = dframe.columns.values\n",
    "    for j in range(0,dframe.shape[1]):\n",
    "        cknan = dframe.iloc[0,j]\n",
    "        if math.isnan(cknan): #Check NaN value at row 0 in column j\n",
    "            naList.append(j)\n",
    "    return naList\n",
    "\n",
    "def checkInf(dframe):\n",
    "    infList = []\n",
    "    colDframe = dframe.columns.values\n",
    "    for j in range(0,len(colDframe)):\n",
    "        cknan = dframe.iloc[0,j]\n",
    "        if math.isinf(cknan): #Check Infinite value at row 0 in column j\n",
    "            infList.append(j)\n",
    "    return infList\n",
    "\n",
    "def checkDupLabel(dframe):\n",
    "    dupLabel = []\n",
    "    for i in range(0,dframe.shape[1]):\n",
    "        label = dframe.columns.values[i]\n",
    "        for j in range(i+1, dframe.shape[1]):\n",
    "            if(label == dframe.columns.values[j]):\n",
    "                print(0)\n",
    "    return dupLabel\n",
    "\n",
    "def lowCorrP(dframe):\n",
    "    label_ = dframe.columns.values\n",
    "    pic50 = dframe.iloc[:,-1]\n",
    "    corr_y = [pearsonr(dframe.iloc[:,i],pic50) for i in range(dframe.shape[1])]\n",
    "    corr_y = [np.abs(corr_y[i][0]) for i in range(dframe.shape[1])]\n",
    "    corr_lim = 0.20\n",
    "    hi_corr = []\n",
    "    for i in range(len(corr_y)):\n",
    "        if corr_y[i] > corr_lim:\n",
    "            hi_corr.append(i)\n",
    "    label_idx = label_[hi_corr]\n",
    "    dtLowCorr = dframe.loc[:,label_idx]\n",
    "    # print(X_train)\n",
    "    print(\"descriptor number after removing low correlation with target: {}\".format(dtLowCorr.shape[1]))\n",
    "    return dtLowCorr\n",
    "\n",
    "def highCorrP(dframe):\n",
    "    # -----------REMOVE FEATURE WITH HIGH CORRELATION TO OTHER FEATURE---------------------\n",
    "    # re-calculate correlation with pic50\n",
    "    label_ = dframe.columns.values\n",
    "    pic50 = dframe.iloc[:,-1]\n",
    "    corr_y = [pearsonr(dframe.iloc[:,i],pic50) for i in range(dframe.shape[1])]\n",
    "    corr_y = [np.abs(corr_y[i][0]) for i in range(dframe.shape[1])]\n",
    "    desc_num = dframe.shape[1]\n",
    "    # calculate correlation for each descriptor\n",
    "    corr_matrix = np.corrcoef(dframe.T)\n",
    "    corr_lim = 0.80\n",
    "    low_corr = np.arange(desc_num).tolist()\n",
    "    tmp = np.arange(desc_num).tolist()\n",
    "    for i in np.arange(desc_num):\n",
    "        tmp.remove(i)\n",
    "        for j in tmp:\n",
    "            corr_ = np.abs(corr_matrix[i,j])\n",
    "            if corr_ >= corr_lim:\n",
    "                if corr_y[i] > corr_y[j]:\n",
    "                    if j in low_corr:\n",
    "                        low_corr.remove(j)\n",
    "                else:\n",
    "                    if i in low_corr:\n",
    "                        low_corr.remove(i)\n",
    "    label_idx = label_[low_corr]\n",
    "    dtHiCorr = dframe.loc[:,label_idx]\n",
    "    print(\"descriptor number after removing high correlation descriptor: {}\".format(dtHiCorr.shape[1]))\n",
    "    return dtHiCorr\n",
    "\n",
    "def dropColumn(dframe, tList):\n",
    "    dropped = pd.DataFrame() #Create empty dataframe\n",
    "    dropped = dframe.drop(dframe.columns[tList], axis=1) #drop column based on list by column\n",
    "    return dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ########## START HERE ##########\n",
    "# #Create Nan Values List\n",
    "# naValues = []\n",
    "# print(\"#Trainset After Concatenated : \", dtTrain.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0. Trainset  3609  |  166  NaN value columns removed\n"
     ]
    }
   ],
   "source": [
    "##### STEP 0 Reduces NAN Values\n",
    "raw = len(dtTrain.columns)\n",
    "dtTrain.dropna(axis=1, how='any', thresh=None, subset=None, inplace=True)\n",
    "print(\"#0. Trainset \", dtTrain.shape[1] , \" | \", raw-dtTrain.shape[1], \" NaN value columns removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1. Trainset  3609  |  2627  similarity value columns removed\n"
     ]
    }
   ],
   "source": [
    "##### STEP 1 Reduces similarity\n",
    "simValList = similarValue(dtTrain)\n",
    "print(\"#1. Trainset \", dtTrain.shape[1] , \" | \", dtTrain.shape[1] - len(simValList) , \" similarity value columns removed\")\n",
    "dtTrain = dropColumn(dtTrain,simValList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2. Trainset  2627  |  1287  standard deviation below 0.95 value columns removed\n"
     ]
    }
   ],
   "source": [
    "##### STEP 2 Reduce columns by Standard Deviation\n",
    "sdList = stdDeviation(dtTrain)\n",
    "print(\"#2. Trainset \", dtTrain.shape[1] , \" | \", dtTrain.shape[1] - len(sdList) , \" standard deviation below 0.95 value columns removed\")\n",
    "dtTrain = dropColumn(dtTrain,sdList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptor number after removing low correlation with target: 1083\n"
     ]
    }
   ],
   "source": [
    "###### STEP 3  Low Correlations\n",
    "dtTrain = lowCorrP(dtTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptor number after removing high correlation descriptor: 73\n"
     ]
    }
   ],
   "source": [
    "###### STEP 4 High Correlations\n",
    "dtTrain = highCorrP(dtTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          VR1_A      AATS8v      AATS1i      AATS5i    ATSC2dv    ATSC5dv  \\\n",
      "0    388.463264  168.096148  145.720280  158.019815  67.716446  -6.822306   \n",
      "1    385.352598  163.066886  145.641023  158.140044  69.903374   3.735943   \n",
      "2    680.973537  199.305434  146.875307  158.089388  12.880883   9.807580   \n",
      "3    210.041446  164.710770  151.225029  160.555110  24.197531 -59.456790   \n",
      "4   3979.637794  204.418517  151.476138  162.994107  16.952909  -6.966759   \n",
      "..          ...         ...         ...         ...        ...        ...   \n",
      "69  3673.716395  208.415286  149.139296  162.905173   6.383802 -20.615868   \n",
      "70   825.440954  202.231340  150.232595  160.681389  21.340265   7.196597   \n",
      "71  1321.776384  196.501512  150.280345  166.188815  26.244898  28.219388   \n",
      "72  3993.597635  205.694681  149.732651  162.523811  14.361983  30.373884   \n",
      "73   449.057218  183.910760  145.008363  157.057215  77.473086 -30.414815   \n",
      "\n",
      "      ATSC6dv    ATSC7dv     ATSC8dv     ATSC2d  ...       TDB10i     RDF35m  \\\n",
      "0  -33.705104 -82.790170  -87.442344   8.759452  ...  1527.493377  13.077664   \n",
      "1  -36.302791 -86.831737 -122.275718   2.095377  ...  1525.903707  12.098395   \n",
      "2   -0.912536 -64.550604  -41.047897   8.231987  ...  1551.999629  10.917638   \n",
      "3  -54.567901 -82.925926  -51.123457   7.114198  ...  1619.499968  10.279575   \n",
      "4  -15.318560 -33.218837   30.135734   3.658972  ...  1499.350890  11.702749   \n",
      "..        ...        ...         ...        ...  ...          ...        ...   \n",
      "69  25.538512 -47.757355  -22.971240   2.560000  ...  1496.044750  11.147349   \n",
      "70 -41.217391 -33.211720  -12.616257   7.965974  ...  1564.694418  10.899556   \n",
      "71 -16.658163 -39.428571  -62.448980   6.061224  ...  1401.732250  14.548272   \n",
      "72   0.782810 -76.047603   -0.848595   2.449587  ...  1515.806377  10.515318   \n",
      "73 -22.277037 -80.312593  -72.350617  12.843457  ...  1487.949715  11.124261   \n",
      "\n",
      "      RDF40m     RDF60m     RDF70m     RDF75m     RDF45s    RNCS.1  MDEC-13.2  \\\n",
      "0   2.500471  11.916735   4.378849   8.291557  30.163957  3.287458   5.726273   \n",
      "1   4.934237  12.641875   5.399668   8.991372  28.509782  3.216475   6.423211   \n",
      "2   2.753623  10.540571   2.803914  10.182094  33.225673  4.248298   2.078258   \n",
      "3   2.355533   7.416363   3.158195   7.597106  28.105172  3.568316   1.529303   \n",
      "4   4.731428  15.522033   4.846049  13.221135  43.290069  2.027855   1.568799   \n",
      "..       ...        ...        ...        ...        ...       ...        ...   \n",
      "69  5.085595  13.935839  11.584502  15.039056  34.543731  3.815654   1.569145   \n",
      "70  3.565559  10.441268   7.176225   9.088391  33.278935  2.619100   3.100863   \n",
      "71  2.657596  15.274075   7.119050  11.696285  48.135107  2.533832   2.368097   \n",
      "72  3.593544  12.380405   6.465128  13.491053  28.701496  2.172855   1.531143   \n",
      "73  1.903341   9.412843   3.700155  11.246921  28.473062  5.078877   3.210079   \n",
      "\n",
      "    pIC50  \n",
      "0   4.456  \n",
      "1   4.347  \n",
      "2   6.065  \n",
      "3   6.886  \n",
      "4   7.796  \n",
      "..    ...  \n",
      "69  7.921  \n",
      "70  7.244  \n",
      "71  8.046  \n",
      "72  8.000  \n",
      "73  5.721  \n",
      "\n",
      "[74 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dtTrain)\n",
    "dtTrain.to_pickle(\"./dtTrain.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
